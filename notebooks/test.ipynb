{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "\n",
    "# Define paths\n",
    "AUDIO_DIR = Path(\"../data/audio\")\n",
    "TRANSCRIPT_DIR = Path(\"../data/transcripts\")\n",
    "\n",
    "# Create transcripts directory if it doesn't exist\n",
    "TRANSCRIPT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio: Morning thoughts 1.m4a\n",
      "Transcript: Morning thoughts 1.md\n",
      "--------------------------------------------------\n",
      "Audio: Morning thoughts 2.m4a\n",
      "Transcript: Morning thoughts 2.md\n",
      "--------------------------------------------------\n",
      "Audio: Morning thoughts 3.m4a\n",
      "Transcript: Morning thoughts 3.md\n",
      "--------------------------------------------------\n",
      "Audio: Morning thoughts 4.m4a\n",
      "Transcript: Morning thoughts 4.md\n",
      "--------------------------------------------------\n",
      "Audio: Morning thoughts 5.m4a\n",
      "Transcript: Morning thoughts 5.md\n",
      "--------------------------------------------------\n",
      "Audio: Morning thoughts 6.m4a\n",
      "Transcript: Morning thoughts 6.md\n",
      "--------------------------------------------------\n",
      "Audio: Morning thoughts 7.m4a\n",
      "Transcript: Morning thoughts 7.md\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_audio_files() -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Get a list of audio files and their corresponding transcript paths.\n",
    "    Returns a list of dictionaries containing file information.\n",
    "    \"\"\"\n",
    "    audio_files = []\n",
    "\n",
    "    for audio_file in sorted(AUDIO_DIR.glob(\"*.m4a\")):\n",
    "        # Extract the base name without extension\n",
    "        base_name = audio_file.stem\n",
    "        # Create corresponding transcript path\n",
    "        transcript_path = TRANSCRIPT_DIR / f\"{base_name}.md\"\n",
    "\n",
    "        audio_files.append(\n",
    "            {\n",
    "                \"audio_file\": audio_file,\n",
    "                \"transcript_path\": transcript_path,\n",
    "                \"base_name\": base_name,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return audio_files\n",
    "\n",
    "\n",
    "# Get list of audio files\n",
    "audio_files = get_audio_files()\n",
    "\n",
    "# Display available files\n",
    "for file_info in audio_files:\n",
    "    print(f\"Audio: {file_info['audio_file'].name}\")\n",
    "    print(f\"Transcript: {file_info['transcript_path'].name}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying transcript for: Morning thoughts 1\n",
      "\n",
      "=== Transcript Content ===\n",
      "\n",
      "\n",
      "Content:\n",
      ". Okay, well, I'd better get started. This will be my first recording in a series of recordings. that I'm doing a little experiment on, actually. I'm gonna see if I can take all of these recordings and then do some sort of analysis on this. The reason I'm doing it is because I think with large language models, the ability to do such an analysis often a large amount of tax. has become possible in the last year or so., maybe this was not the best part to come down there for so many crows. Okay. And I just think it would be interesting to see what sort of analysis I could make on such a corpus of text. It's a little bit awkward for me. I mean, I don't know exactly what I'm going to say. They're going to be. He's, they're going to be very free form. No particular topic. Just talking about life, the future, whatever I feel like, to be honest. Hopefully the analysis at the end will be able to pass what I want to say. I've already done a short test recorder. And the automatic transcription doesn't transcribe exactly what I'm saying. So I'm speaking a little bit more clearly that I would to normally. I might have to check check those transcriptions thoroughly before I do any analysis, but there we go. That's what it is. So, another reason why I'm doing this is because I've had a lot of shorts about the future about AI about my career path, and it both frightens me and excites me in little measure. These large language modellers, they they can do what they can do what we thought was magic two years ago. It's absolutely incredible technology, and I think people are seeing going on. It's potential, but also, I think people are sleeping on. It's potential dangers. I'm worried for my own influence status, although I am a software engineer, I guess you could call me a software engineer. Really, I'm a data analyst, kind of data scientist. I can do a little bit of coding in Python, and I'll be playing with these LLM. for the past. past year, a year and a half. Under the beginning, I thought, well, this is I need trick. I thought this is myf. But as I play with a more, I realise that you can do all sorts of magical things. automatic tech andorization. I think is wonderful.. The way it seems to be conscious. When it replies to you, it's this really amazing her daughter, I'm little bit scary. I just,. So, yes, I'm a little bit worried for my own employment security. I wonder what's going to happen in the future and it's left me with this feeling of like I said, a mixture of excitement and deep anxiety. Excitement at the possibilities, anxiety at of the future I' hold. I want to dive deeper into this area. AI. I think there's a lot of money to be made. But every time I think of an idea, I second guess myself, or someone who's already done it. It seems as if, knowledge now is so cheap. and all of the AI rappers that you can think of have already been made or already dying. A personality is not one of quick thinking, well, not quick thinking, but I'm hardly I hardly make action very easily. I'm much more of a thinker, introspective. In some cases, that's a good quality. It means that whatever decision I do make, I've deeply thought about and tends to be a lot more solid. based on evidence and nationality. It also means that very good ideas get lost and never get executed. I find myself thinking about amazing ideas, amazing applications for AI, and yet never taking them into action. I get thoroughly stuck in a cycular short. This is a great idea. Maybe I should do this. I start throwing some code on the page and realise that this is not sog a idea at all and then I I stop.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_markdown_content(content: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Parse markdown content into structured data.\n",
    "    Returns a list of dictionaries containing parsed content.\n",
    "    \"\"\"\n",
    "    sections = []\n",
    "    current_section = {\"text\": [], \"metadata\": {}}\n",
    "    \n",
    "    lines = content.split('\\n')\n",
    "    for line in lines:\n",
    "        # Skip empty lines\n",
    "        if not line.strip():\n",
    "            continue\n",
    "            \n",
    "        # Check for metadata (assuming metadata is in format \"Key: Value\")\n",
    "        if ': ' in line and not line.startswith('#'):\n",
    "            key, value = line.split(': ', 1)\n",
    "            current_section[\"metadata\"][key.strip()] = value.strip()\n",
    "        # Check for headers\n",
    "        elif line.startswith('#'):\n",
    "            # If we have content in the current section, save it\n",
    "            if current_section[\"text\"] or current_section[\"metadata\"]:\n",
    "                sections.append(current_section)\n",
    "                current_section = {\"text\": [], \"metadata\": {}}\n",
    "            current_section[\"metadata\"][\"header\"] = line.lstrip('#').strip()\n",
    "        else:\n",
    "            current_section[\"text\"].append(line.strip())\n",
    "    \n",
    "    # Add the last section if it has content\n",
    "    if current_section[\"text\"] or current_section[\"metadata\"]:\n",
    "        sections.append(current_section)\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def read_transcript(transcript_path: Path) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Read a markdown transcript file and return its structured contents.\n",
    "    Returns an empty list if the file doesn't exist.\n",
    "    \"\"\"\n",
    "    if transcript_path.exists():\n",
    "        with open(transcript_path, \"r\", encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            return parse_markdown_content(content)\n",
    "    return []\n",
    "\n",
    "def display_transcript_content(transcript_data: List[Dict]):\n",
    "    \"\"\"\n",
    "    Display the contents of a transcript in a formatted way.\n",
    "    \"\"\"\n",
    "    if not transcript_data:\n",
    "        print(\"No transcript data available.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n=== Transcript Content ===\\n\")\n",
    "    \n",
    "    for section in transcript_data:\n",
    "        # Display metadata\n",
    "        if section[\"metadata\"]:\n",
    "            print(\"Metadata:\")\n",
    "            for key, value in section[\"metadata\"].items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "        \n",
    "        # Display text content\n",
    "        if section[\"text\"]:\n",
    "            print(\"\\nContent:\")\n",
    "            print(\"\\n\".join(section[\"text\"]))\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Example usage:\n",
    "# Choose the first transcript to display\n",
    "if audio_files:\n",
    "    first_transcript = read_transcript(audio_files[0][\"transcript_path\"])\n",
    "    print(f\"Displaying transcript for: {audio_files[0]['base_name']}\")\n",
    "    display_transcript_content(first_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
