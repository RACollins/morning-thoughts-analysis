Okay, well, I'd better get started. This will be my first recording in a series of recordings that I'm doing a little experiment on, actually. I'm going to see if I can take all of these recordings and then do some sort of analysis on them.

The reason I'm doing it is because I think with large language models, the ability to do such an analysis on a large amount of text has become possible in the last year or so. Maybe this was not the best part to come down—there are so many crows. Okay.

I just think it would be interesting to see what sort of analysis I could make on such a corpus of text. It's a little bit awkward for me. I mean, I don't know exactly what I'm going to say. They're going to be very free-form. No particular topic. Just talking about life, the future, whatever I feel like, to be honest. Hopefully, the analysis at the end will be able to parse what I want to say.

I've already done a short test recording, and the automatic transcription doesn't transcribe exactly what I'm saying. So I'm speaking a little bit more clearly than I would normally. I might have to check those transcriptions thoroughly before I do any analysis, but there we go. That's what it is.

Another reason why I'm doing this is because I've had a lot of thoughts about the future, about AI, about my career path, and it both frightens me and excites me in equal measure. These large language models—they can do what we thought was magic two years ago. It's absolutely incredible technology, and I think people are seeing its potential. But also, I think people are sleeping on its potential dangers.

I'm worried for my own influence and status. Although I am a software engineer—I guess you could call me a software engineer—really, I'm a data analyst, kind of a data scientist. I can do a little bit of coding in Python, and I've been playing with these LLMs for the past year, year and a half.

At the beginning, I thought, well, this is a neat trick. I thought, this is myself. But as I played with it more, I realized that it can do all sorts of magical things. Automatic text categorization, I think, is wonderful. The way it seems to be conscious when it replies to you—it's this really amazing phenomenon, a little bit scary.

So, yes, I'm a little bit worried for my own employment security. I wonder what's going to happen in the future, and it's left me with this feeling of, like I said, a mixture of excitement and deep anxiety. Excitement at the possibilities, anxiety at the future I hold.

I want to dive deeper into this area of AI. I think there's a lot of money to be made. But every time I think of an idea, I second-guess myself, or someone has already done it. It seems as if knowledge now is so cheap, and all of the AI wrappers that you can think of have already been made or are already dying.

My personality is not one of quick thinking. Well, not quick thinking, but I hardly make decisions very easily. I'm much more of a thinker, introspective. In some cases, that's a good quality. It means that whatever decision I do make, I've deeply thought about, and it tends to be a lot more solid, based on evidence and rationality.

It also means that very good ideas get lost and never get executed. I find myself thinking about amazing ideas, amazing applications for AI, and yet never taking them into action. I get thoroughly stuck in a circular thought: "This is a great idea. Maybe I should do this." I start throwing some code on the page and realize that this is not such a good idea at all, and then I stop.
